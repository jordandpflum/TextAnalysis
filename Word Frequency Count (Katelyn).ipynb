{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import io\n",
    "import csv\n",
    "from pandas import DataFrame\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACURA</td>\n",
       "      <td>INTEGRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACURA</td>\n",
       "      <td>LEGEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACURA</td>\n",
       "      <td>VIGOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand    model\n",
       "0  ACURA  INTEGRA\n",
       "1  ACURA   LEGEND\n",
       "2  ACURA    VIGOR"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create df for brands and models\n",
    "df = pd.read_csv(\"scrapedData.csv\", index_col=0)\n",
    "cars = pd.read_csv(\"carmodelsandbrands.csv\",header =None)\n",
    "# create columns for brand and model\n",
    "cars.columns = ['brand', 'model']\n",
    "models = cars['model'] \n",
    "brands = cars['brand']\n",
    "cars['model'] = cars['model'].str.upper() \n",
    "cars['brand'] = cars['brand'].str.upper() \n",
    "cars[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for brands, models\n",
    "brand_dict = {models[i]:brands[i] for i in range(len(models))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-04-02T13:43:55+00:00</td>\n",
       "      <td>fintail</td>\n",
       "      <td>This isn't totally new, but I saw my first Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-04-02T13:52:23+00:00</td>\n",
       "      <td>andre1969</td>\n",
       "      <td>I saw both a Colorado and a Malibu in DC. I kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-04-02T15:25:54+00:00</td>\n",
       "      <td>lemko</td>\n",
       "      <td>...but I saw a Mazda 3 last week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-04-02T15:28:12+00:00</td>\n",
       "      <td>andre1969</td>\n",
       "      <td>sometimes though, at a quick glance it takes m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-04-02T16:07:00+00:00</td>\n",
       "      <td>PF_Flyer</td>\n",
       "      <td>Yea, we can have some retroactive sightings to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date     author  \\\n",
       "0  2004-04-02T13:43:55+00:00    fintail   \n",
       "1  2004-04-02T13:52:23+00:00  andre1969   \n",
       "2  2004-04-02T15:25:54+00:00      lemko   \n",
       "3  2004-04-02T15:28:12+00:00  andre1969   \n",
       "4  2004-04-02T16:07:00+00:00   PF_Flyer   \n",
       "\n",
       "                                                text  \n",
       "0  This isn't totally new, but I saw my first Sci...  \n",
       "1  I saw both a Colorado and a Malibu in DC. I kn...  \n",
       "2                  ...but I saw a Mazda 3 last week.  \n",
       "3  sometimes though, at a quick glance it takes m...  \n",
       "4  Yea, we can have some retroactive sightings to...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data and rename columns\n",
    "df = pd.read_csv('scrapedData.csv')\n",
    "df.rename(columns = {'Date': 'date'}, inplace = True)\n",
    "df.drop(columns=['PageCommentNumber'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert comments column to strings\n",
    "df['text'] = df['text'].apply(str)\n",
    "# create a list of the comments\n",
    "comments = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_word_frequency(wordlist):\n",
    " \n",
    "    # replace certain characters with spaces\n",
    "    wordlist = wordlist.replace(\"/\", \" \")\n",
    "    wordlist = wordlist.replace(\"_\", \" \")\n",
    "    wordlist = wordlist.replace(\"'\", \" \")\n",
    "        \n",
    "    # create list of words for the comment\n",
    "    tokens = nltk.tokenize.word_tokenize(wordlist)\n",
    " \n",
    "    # get list of English stop words\n",
    "    take_out = stopwords.words('english')\n",
    "    take_out = [word.upper() for word in take_out]\n",
    " \n",
    "    # convert word to uppercase\n",
    "    tokens = [word.upper() for word in tokens]\n",
    " \n",
    "    # filter out stop words and punctuation from tokens list\n",
    "    tokens = [word for word in tokens if word not in take_out]\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    tokens = [word for word in tokens if word[0] not in string.punctuation]\n",
    "    \n",
    "    # replace car models with brands\n",
    "    tokens_replaced = []\n",
    "    for item in tokens:\n",
    "        if item in brand_dict.keys():\n",
    "            tokens_replaced.append(brand_dict[item])\n",
    "        else:\n",
    "            tokens_replaced.append(item)\n",
    " \n",
    "    # get word frequency distribution\n",
    "    word_frequencies = nltk.FreqDist(tokens_replaced)\n",
    " \n",
    "    # sort word frequency distribution by number of times each word occurs\n",
    "    sorted_counts = sorted(word_frequencies.items() , key = lambda x: x[1] ,\n",
    "                           reverse = True)\n",
    " \n",
    "    return sorted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('SAW', 2),\n",
       "  ('TOYOTA', 2),\n",
       "  ('TOTALLY', 1),\n",
       "  ('NEW', 1),\n",
       "  ('FIRST', 1),\n",
       "  ('DAY', 1),\n",
       "  ('BLACK', 1),\n",
       "  ('BOXY', 1),\n",
       "  ('BELLINGHAM', 1),\n",
       "  ('WA', 1),\n",
       "  ('WAYS', 1),\n",
       "  ('ACTUALLY', 1),\n",
       "  ('SELL', 1),\n",
       "  ('THINK', 1),\n",
       "  ('COUNTS', 1)]]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list with comment sublists that include words and frequency counts\n",
    "preresults = [x for x in comments if x != '']\n",
    "results = [get_word_frequency(x) for x in preresults]\n",
    "results[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SAW', 'TOYOTA', 'TOTALLY', 'NEW', 'FIRST']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of unique words in posts\n",
    "allwords = []\n",
    "for comment in results:\n",
    "    for word in comment:\n",
    "        # Append Word form (Word, Occurance) tuple\n",
    "        allwords.append(word[0])\n",
    "allwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW</td>\n",
       "      <td>3927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ONE</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAR</td>\n",
       "      <td>3534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAW</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIKE</td>\n",
       "      <td>3099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  count\n",
       "0   NEW   3927\n",
       "1   ONE   3547\n",
       "2   CAR   3534\n",
       "3   SAW   3465\n",
       "4  LIKE   3099"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get word frequency across all comments (counting each word only once per post)\n",
    "overall_text = ' '.join(allwords)\n",
    "top_words = get_word_frequency(overall_text)\n",
    "overall_freq = DataFrame(top_words,columns=['word','count'])\n",
    "overall_freq.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export to csv\n",
    "overall_freq.to_csv(r'C:\\Users\\katel\\OneDrive\\Desktop\\Text Analysis\\OverallWordFreq.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jenny Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "pairs = []\n",
    "for i in results:\n",
    "    pairs.append(itertools.permutations([i, 2]))\n",
    "    \n",
    "dictionary_of_pairs = {}\n",
    "\n",
    "for i in pairs:\n",
    "    dictionary_of_pairs.update\n",
    "    \n",
    "def Lift():\n",
    "    for i in pairs():\n",
    "        word_1 = i\n",
    "        word_2 = i+1\n",
    "    lift_dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<itertools.permutations at 0x24d5449e2e8>,\n",
       " <itertools.permutations at 0x24d5449e048>,\n",
       " <itertools.permutations at 0x24d5449e828>,\n",
       " <itertools.permutations at 0x24d5449e288>,\n",
       " <itertools.permutations at 0x24d5449e948>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
