{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import io\n",
    "import csv\n",
    "from pandas import DataFrame\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-04-02T13:43:55+00:00</td>\n",
       "      <td>fintail</td>\n",
       "      <td>This isn't totally new, but I saw my first Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-04-02T13:52:23+00:00</td>\n",
       "      <td>andre1969</td>\n",
       "      <td>I saw both a Colorado and a Malibu in DC. I kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-04-02T15:25:54+00:00</td>\n",
       "      <td>lemko</td>\n",
       "      <td>...but I saw a Mazda 3 last week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-04-02T15:28:12+00:00</td>\n",
       "      <td>andre1969</td>\n",
       "      <td>sometimes though, at a quick glance it takes m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-04-02T16:07:00+00:00</td>\n",
       "      <td>PF_Flyer</td>\n",
       "      <td>Yea, we can have some retroactive sightings to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date     author  \\\n",
       "0  2004-04-02T13:43:55+00:00    fintail   \n",
       "1  2004-04-02T13:52:23+00:00  andre1969   \n",
       "2  2004-04-02T15:25:54+00:00      lemko   \n",
       "3  2004-04-02T15:28:12+00:00  andre1969   \n",
       "4  2004-04-02T16:07:00+00:00   PF_Flyer   \n",
       "\n",
       "                                                text  \n",
       "0  This isn't totally new, but I saw my first Sci...  \n",
       "1  I saw both a Colorado and a Malibu in DC. I kn...  \n",
       "2                  ...but I saw a Mazda 3 last week.  \n",
       "3  sometimes though, at a quick glance it takes m...  \n",
       "4  Yea, we can have some retroactive sightings to...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data and rename columns\n",
    "df = pd.read_csv('scrapedData.csv')\n",
    "df.rename(columns = {'Date': 'date'}, inplace = True)\n",
    "df.drop(columns=['PageCommentNumber'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert comments column to strings\n",
    "df['text'] = df['text'].apply(str)\n",
    "# create a list of the comments\n",
    "comments = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_word_frequency(wordlist):\n",
    " \n",
    "    # replace slash with space\n",
    "    wordlist = wordlist.replace(\"/\", \" \")\n",
    "    wordlist = wordlist.replace(\"_\", \" \")\n",
    "    wordlist = wordlist.replace(\"'\", \" \")\n",
    "    wordlist = wordlist.replace(\"-\", \" \")\n",
    "        \n",
    "    # create list of words for the comment\n",
    "    tokens = nltk.tokenize.word_tokenize(wordlist)\n",
    " \n",
    "    # Get list of English stop words\n",
    "    take_out = stopwords.words('english')\n",
    "    take_out = [word.upper() for word in take_out]\n",
    " \n",
    "    # Convert word to uppercase\n",
    "    tokens = [word.upper() for word in tokens]\n",
    " \n",
    "    # Filter out stop words and punctuation from tokens list\n",
    "    tokens = [word for word in tokens if word not in take_out]\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    tokens = [word for word in tokens if word[0] not in string.punctuation]\n",
    " \n",
    "    # Get word frequency distribution\n",
    "    word_frequencies = nltk.FreqDist(tokens)\n",
    " \n",
    "    # Sort word frequency distribution by number of times each word occurs\n",
    "    sorted_counts = sorted(word_frequencies.items() , key = lambda x: x[1] ,\n",
    "                           reverse = True)\n",
    " \n",
    "    return sorted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('SAW', 2),\n",
       "  ('TOTALLY', 1),\n",
       "  ('NEW', 1),\n",
       "  ('FIRST', 1),\n",
       "  ('SCION', 1),\n",
       "  ('XB', 1),\n",
       "  ('DAY', 1),\n",
       "  ('BLACK', 1),\n",
       "  ('BOXY', 1),\n",
       "  ('BELLINGHAM', 1),\n",
       "  ('WA', 1),\n",
       "  ('WAYS', 1),\n",
       "  ('ACTUALLY', 1),\n",
       "  ('SELL', 1),\n",
       "  ('THINK', 1),\n",
       "  ('COUNTS', 1)]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preresults = [x for x in comments if x != '']\n",
    "results = [get_word_frequency(x) for x in preresults]\n",
    "results[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object doesn't support item deletion",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-5a45e9db2699>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomment\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mdel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object doesn't support item deletion"
     ]
    }
   ],
   "source": [
    "hmm = []\n",
    "for comment in results:\n",
    "    for word in comment:\n",
    "        list(word)\n",
    "        del(word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('SAW', 2),\n",
       "  ('TOTALLY', 1),\n",
       "  ('NEW', 1),\n",
       "  ('FIRST', 1),\n",
       "  ('SCION', 1),\n",
       "  ('XB', 1),\n",
       "  ('DAY', 1),\n",
       "  ('BLACK', 1),\n",
       "  ('BOXY', 1),\n",
       "  ('BELLINGHAM', 1),\n",
       "  ('WA', 1),\n",
       "  ('WAYS', 1),\n",
       "  ('ACTUALLY', 1),\n",
       "  ('SELL', 1),\n",
       "  ('THINK', 1),\n",
       "  ('COUNTS', 1)],\n",
       " [('COLORADO', 2),\n",
       "  ('MALIBU', 2),\n",
       "  ('TIME', 2),\n",
       "  ('SEEN', 2),\n",
       "  ('SAW', 1),\n",
       "  ('DC', 1),\n",
       "  ('KNOW', 1),\n",
       "  ('NEITHER', 1),\n",
       "  ('ONE', 1),\n",
       "  ('CUTTING', 1),\n",
       "  ('EDGE', 1),\n",
       "  ('NEWNESS', 1),\n",
       "  ('LIKE', 1),\n",
       "  ('SECOND', 1),\n",
       "  ('ROADS', 1),\n",
       "  ('MAYBE', 1),\n",
       "  ('THIRD', 1),\n",
       "  ('NEW', 1)]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of unique words in posts\n",
    "allwords = []\n",
    "for comment in results:\n",
    "    for word in comment:\n",
    "        # Append Word form (Word, Occurance) tuple\n",
    "        allwords.append(word[0])\n",
    "allwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word frequency across all comments (counting each word only once per post)\n",
    "overall_text = ' '.join(allwords)\n",
    "top_words = get_word_frequency(overall_text)\n",
    "overall_freq = DataFrame(top_words,columns=['word','count'])\n",
    "overall_freq.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export to csv\n",
    "overall_freq.to_csv(r'C:\\Users\\katel\\OneDrive\\Desktop\\Text Analysis\\OverallWordFreq.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jenny Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "pairs = []\n",
    "for i in results:\n",
    "    pairs.append(itertools.permutations([i, 2]))\n",
    "    \n",
    "dictionary_of_pairs = {}\n",
    "\n",
    "for i in pairs:\n",
    "    dictionary_of_pairs.update\n",
    "    \n",
    "def Lift():\n",
    "    for i in pairs():\n",
    "        word_1 = i\n",
    "        word_2 = i+1\n",
    "    lift_dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
